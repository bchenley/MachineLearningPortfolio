{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","authorship_tag":"ABX9TyPNh2EkhYY7QzArHlOOZ9Ty"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# pytorch\n","!pip install pytorch_lightning torchvision torchaudio --quiet\n","\n","# imaging libraries\n","!pip install SimpleITK nibabel monai --quiet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4wJaCWVKuXq","executionInfo":{"status":"ok","timestamp":1699648095238,"user_tz":300,"elapsed":15587,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}},"outputId":"765ee081-9ff4-46da-e063-f90ba84cf261"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m805.2/805.2 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"QCMQH-NPEF2P","executionInfo":{"status":"ok","timestamp":1699648101418,"user_tz":300,"elapsed":6182,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"outputs":[],"source":["# google drive\n","from google.colab import drive\n","\n","# Data libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","# import supporting libraries\n","import os\n","import tarfile\n","from PIL import Image\n","from tqdm import tqdm\n","import tarfile\n","from io import BytesIO\n","from concurrent.futures import ThreadPoolExecutor\n","import pickle\n","\n","# Visualization libraries\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# modeling librarires\n","import torch, torchvision as tv, torchaudio as ta\n","import pytorch_lightning as pl\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics import confusion_matrix\n","\n","# imaging libraries\n","import SimpleITK as sitk, nibabel as nib, monai"]},{"cell_type":"code","source":["drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H03OVlKoJbNz","executionInfo":{"status":"ok","timestamp":1699648127247,"user_tz":300,"elapsed":25839,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}},"outputId":"6190d2ba-9d07-4c88-abae-4088c60f4e71"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["def list_folders_subfolders(directory):\n","  for root, dirs, files in os.walk(directory):\n","    level = root.replace(directory, '').count(os.sep)\n","    indent = ' ' * 4 * (level)\n","    print('{}{}/'.format(indent, os.path.basename(root)))\n","    subindent = ' ' * 4 * (level + 1)\n","    for f in files:\n","      print('{}{}'.format(subindent, f))"],"metadata":{"id":"gXAPzzcSUioA","executionInfo":{"status":"ok","timestamp":1699648127247,"user_tz":300,"elapsed":6,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def dice(y_true, y_pred):\n","  card_interaction = np.logical_and(y_true, y_pred).sum()\n","\n","  card_true = np.bool_(y_true).sum()\n","  card_pred = np.bool_(y_pred).sum()\n","\n","  dsc = (2. * card_interaction / (card_true + card_pred))\n","\n","  return dsc\n","\n","def mse(y_true, y_pred):\n","  return ((y_true - y_pred)**2).mean()"],"metadata":{"id":"YedtwD7yGBcw","executionInfo":{"status":"ok","timestamp":1699648127247,"user_tz":300,"elapsed":5,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def register_image(fixed_image, moving_image,\n","                   transform_type = 'similarity',\n","                   metric = 'mmi',\n","                   num_bins = 50,\n","                   learning_rate = 1.0,\n","                   max_iters = 200,\n","                   interp_method = 'linear',\n","                   default_pixel_value = 0.,\n","                   min_convergence = 1e-6, convergence_window = 20,\n","                   sitk_dtype = sitk.sitkFloat32):\n","\n","  device, final_dtype = None, None\n","  # Get fixed image as sitk array\n","  if isinstance(fixed_image, np.ndarray):\n","    if fixed_image.dtype == np.float16:\n","      final_dtype = np.float16\n","    elif fixed_image.dtype == np.float32:\n","      final_dtype = np.float32\n","    elif fixed_image.dtype == np.float64:\n","      final_dtype = np.float64\n","\n","    fixed_image = sitk.GetImageFromArray(fixed_image)\n","\n","  elif isinstance(fixed_image, torch.Tensor):\n","    if fixed_image.dtype == torch.float16:\n","      final_dtype = torch.float16\n","    elif fixed_image.dtype == np.float32:\n","      final_dtype = torch.float32\n","    elif fixed_image.dtype == np.float64:\n","      final_dtype = torch.float64\n","\n","    device = fixed_image.device\n","    fixed_image = sitk.GetImageFromArray(fixed_image.cpu().numpy())\n","\n","  # Get moving image as sitk array\n","  if isinstance(moving_image, str):\n","    moving_image = sitk.ReadImage(moving_image, sitk_dtype)\n","  elif isinstance(moving_image, np.ndarray):\n","    moving_image = sitk.GetImageFromArray(moving_image)\n","  elif isinstance(moving_image, torch.Tensor):\n","    moving_image = sitk.GetImageFromArray(moving_image.cpu())\n","\n","  assert fixed_image.GetSize() == moving_image.GetSize(), \"Image sizes do not match\"\n","  assert fixed_image.GetSpacing() == moving_image.GetSpacing(), \"Image spacings do not match\"\n","  assert fixed_image.GetDimension() == moving_image.GetDimension(), \"Image dimensions do not match\"\n","\n","  # Instantiate registration method\n","  R = sitk.ImageRegistrationMethod()\n","\n","  # Set up metric\n","  if metric == 'mmi':\n","    R.SetMetricAsMattesMutualInformation(num_bins)\n","  elif metric == 'ms':\n","    R.SetMetricAsMeanSquares()\n","  elif metric == 'jhmi':\n","    R.SetMetricAsJointHistogramMutualInformation(num_bins)\n","  else:\n","    raise ValueError(f\"The metric ({metric}) must be 'mmi', 'ms', or 'jhmi'.\")\n","\n","  # Set optimizer\n","  R.SetOptimizerAsGradientDescent(learningRate = learning_rate,\n","                                  numberOfIterations = max_iters,\n","                                  convergenceMinimumValue = min_convergence,\n","                                  convergenceWindowSize = convergence_window)\n","\n","  # Define transform\n","  if transform_type == 'similarity':\n","    transform = sitk.Similarity3DTransform()\n","  elif transform_type == 'euler':\n","    transform = sitk.Euler3DTransform()\n","  elif transform_type == 'translation':\n","    transform = sitk.TranslationTransform()\n","  elif transform_type == 'versor':\n","    transform = sitk.VersorTransform()\n","  elif transform_type == 'versorrigid':\n","    transform = sitk.VersorRigid3DTransform()\n","  elif transform_type == 'scale':\n","    transform = sitk.ScaleTransform()\n","  elif transform_type == 'scaleversor':\n","    transform = sitk.ScaleVersor3DTransform()\n","  elif transform_type == 'scaleskewversor':\n","    transform = sitk.ScaleSkewVersor3DTransform()\n","  elif transform_type == 'composescaleskewversor':\n","    transform = sitk.ComposeScaleSkewVersor3DTransform()\n","  elif transform_type == 'affine':\n","    transform = sitk.AffineTransform()\n","  elif transform_type == 'bspline':\n","    transform = sitk.BSplineTransform()\n","  elif transform_type == 'displacement':\n","    transform = sitk.DisplacementFieldTransform()\n","  elif transform_type == 'composite':\n","    transform = sitk.CompositeTransform()\n","\n","  # Align centers of fixed and moving image\n","  initial_transform = sitk.CenteredTransformInitializer(fixedImage = fixed_image,\n","                                                        movingImage = moving_image,\n","                                                        transform = transform)\n","\n","  R.SetInitialTransform(initial_transform)\n","\n","  # Set scales for optimization\n","  R.SetOptimizerScalesFromIndexShift()\n","\n","  # Set up interpolator\n","  if interp_method == 'linear':\n","    interpolator = sitk.sitkLinear\n","  elif interp_method == 'nn':\n","    interpolator = sitk.sitkNearestNeighbor\n","  elif interp_method == 'spline':\n","    interpolator = sitk.sitkBSpline\n","  else:\n","    raise ValueError(f\"The interpolator ({interpolator}) must be 'linear', 'nn', or 'spline'.\")\n","\n","  R.SetInterpolator(interpolator)\n","\n","  # Set progress\n","  metric_values = []\n","\n","  def command_iteration(method):\n","\n","    metric_values.append(method.GetMetricValue())\n","\n","    print(f\"Iter. {method.GetOptimizerIteration():3} \"\n","          + f\"= {metric_values[-1]:.4f} \")\n","          # + f\": {method.GetOptimizerPosition()}\")\n","\n","  R.AddCommand(sitk.sitkIterationEvent, lambda: command_iteration(R))\n","\n","  # Set transform\n","  final_transform = R.Execute(fixed = fixed_image, moving = moving_image)\n","\n","  print(final_transform)\n","  print(f\"Optimizer stop condition: {R.GetOptimizerStopConditionDescription()}\")\n","  print(f\"Iteration: {R.GetOptimizerIteration()}\")\n","  print(f\"Metric: {R.GetMetricValue():.4f}\")\n","\n","  # Apply transformation to image and interpolate the result\n","  resampler = sitk.ResampleImageFilter()\n","  resampler.SetReferenceImage(fixed_image)\n","  resampler.SetInterpolator(interpolator)\n","  resampler.SetDefaultPixelValue(default_pixel_value)\n","  resampler.SetTransform(final_transform)\n","\n","  output_image = resampler.Execute(moving_image)\n","\n","  # Convert moving image to original dtype\n","  if final_dtype in [torch.float16, torch.float32, torch.float64]:\n","    output_image = torch.tensor(sitk.GetArrayFromImage(output_image)).to(device = device,\n","                                                                         dtype = final_dtype)\n","  elif final_dtype in [np.float16, np.float32, np.float64]:\n","    output_image = sitk.GetArrayFromImage(output_image).astype(final_dtype)\n","\n","\n","  return output_image, metric_values\n","\n","def register_subject_images(images,\n","                            fixed_image_idx = 0,\n","                            normalize_images = False,\n","                            transform_type = 'similarity',\n","                            metric = 'mmi',\n","                            num_bins = 50,\n","                            learning_rate = 1.0,\n","                            max_iters = 200,\n","                            interp_method = 'linear',\n","                            default_pixel_value = 0.,\n","                            min_convergence = 1e-6, convergence_window = 20,\n","                            sitk_dtype = sitk.sitkFloat32):\n","\n","  num_subjects = len(images)\n","  num_images = images[0]['images'].shape[-1]\n","\n","  moving_image_idx = np.where(np.arange(num_images) != fixed_image_idx)[0]\n","\n","  for i,subject_images in enumerate(images):\n","    subject_images['scaler'] = None\n","    if normalize_images:\n","      subject_images['scaler'] = []\n","      for i in range(num_images):\n","        scaler = MinMaxScaler(feature_range = (0, 1))\n","\n","        image_i = subject_images['image'][:, :, :, i]\n","        if isinstance(image_i, torch.Tensor):\n","          image_is = torch.tensor(scaler.fit_transform(image_i.cpu().reshape(-1, 1)).reshape(image_i.shape)).to(image_i.device, image_i.dtype)\n","        else:\n","          image_is = scaler.fit_transform(image_i.cpu().reshape(-1, 1)).reshape(image_i.shape)\n","\n","        subject_images['images'][:, :, :, i] = image_is\n","        subject_images['scaler'].append(scaler)\n","\n","    fixed_image = subject_images['images'][:, :, :, fixed_image_idx]\n","\n","    for idx in moving_image_idx:\n","      print(f\"Registering image {idx+1} to image {fixed_image_idx+1} for subject {subject_images['id']} ({i+1}/{num_subjects}))\")\n","\n","      subject_images['images'][:, :, :, idx], _ = register_image(fixed_image = fixed_image,\n","                                                                  moving_image = subject_images['images'][:, :, :, idx],\n","                                                                  transform_type = transform_type,\n","                                                                  metric = metric,\n","                                                                  num_bins = num_bins,\n","                                                                  learning_rate = learning_rate,\n","                                                                  max_iters = max_iters,\n","                                                                  interp_method = interp_method,\n","                                                                  default_pixel_value = default_pixel_value,\n","                                                                  min_convergence = min_convergence,\n","                                                                  convergence_window = convergence_window,\n","                                                                  sitk_dtype = sitk_dtype)\n","\n","  return images"],"metadata":{"id":"SV0O_raae1Ng","executionInfo":{"status":"ok","timestamp":1699648127247,"user_tz":300,"elapsed":5,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["\n","def get_images(image_path, dtype=np.float32):\n","    # Load the NIfTI file using nibabel\n","    images = nib.load(image_path)\n","\n","    # Access the data from the NIfTI file and convert it to the specified data type\n","    data = images.get_fdata().astype(dtype)\n","\n","    # Return the image data array\n","    return data\n","\n","def access_images(task_path,\n","                  image_dir='imagesTr/',\n","                  label_dir='labelsTr/',\n","                  dtype=None,\n","                  sample_size=None, random_seed=42,\n","                  register_images=False,\n","                  fixed_image_idx=0,\n","                  normalize_images=False,\n","                  transform_type='similarity',\n","                  metric='mmi',\n","                  num_bins=50,\n","                  learning_rate=1.0,\n","                  max_iters=200,\n","                  interp_method='linear',\n","                  default_pixel_value=0.,\n","                  min_convergence=1e-6, convergence_window=20,\n","                  sitk_dtype=sitk.sitkFloat32):\n","\n","    # Construct the dataset and label paths from the given directories\n","    dataset_path = os.path.join(task_path, image_dir)\n","    label_path = None\n","    if 'Tr' in image_dir:\n","        label_path = os.path.join(task_path, label_dir)\n","\n","    # List all NIfTI files in the dataset_path that match the criteria\n","    nii_list = [nii for nii in os.listdir(dataset_path) if ('nii' in nii) and nii.startswith('BRATS')]\n","\n","    # Sample a subset of files if a sample size is specified\n","    if sample_size is not None:\n","        if random_seed is not None: np.random.seed(random_seed)\n","        np.random.shuffle(nii_list)\n","        nii_list = nii_list[:sample_size]\n","\n","    # Get the total number of subjects to process\n","    num_subjects = len(nii_list)\n","\n","    # Initialize an empty list to hold the data\n","    data = []\n","    for i, image_file in enumerate(tqdm(nii_list, desc=\"Loading NIfTI files\", unit='file')):\n","\n","        # Extract the ID from the filename\n","        id = image_file.split('_')[1].split('.')[0]\n","\n","        # Append a new dictionary to hold data for the current subject\n","        data.append({})\n","\n","        # Assign the extracted ID to the current subject's data\n","        data[-1]['id'] = id\n","\n","        # Retrieve the image data using the get_images function\n","        data[-1]['images'] = get_images(os.path.join(dataset_path, image_file))\n","\n","        # Register images if specified\n","        if register_images:\n","            # Get the number of images (e.g., time points or modalities)\n","            num_images = data[-1]['images'].shape[-1]\n","\n","            # Determine the indices of images that are not the fixed image\n","            moving_image_idx = np.where(np.arange(num_images) != fixed_image_idx)[0]\n","\n","            # Initialize the image scaler if image normalization is needed\n","            data[-1]['image_scaler'] = None\n","            if normalize_images:\n","                data[-1]['image_scaler'] = []\n","                for j in range(num_images):\n","                    # Initialize the MinMaxScaler\n","                    scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","                    # Retrieve the j-th image from the current subject\n","                    image_j = data[-1]['images'][:, :, :, j]\n","                    if isinstance(image_j, torch.Tensor):\n","                        # Normalize the tensor image and retain its type and device\n","                        image_js = torch.tensor(scaler.fit_transform(image_j.cpu().reshape(-1, 1))\n","                                                .reshape(image_j.shape)).to(image_j.device, image_j.dtype)\n","                    else:\n","                        # Normalize the numpy array image\n","                        image_js = scaler.fit_transform(image_j.reshape(-1, 1)).reshape(image_j.shape)\n","\n","                    # Update the j-th image with the normalized image\n","                    data[-1]['images'][:, :, :, j] = image_js\n","                    # Append the scaler to the list of scalers for future inverse transformation if necessary\n","                    data[-1]['image_scaler'].append(scaler)\n","\n","            # Set the fixed image for registration\n","            fixed_image = data[-1]['images'][:, :, :, fixed_image_idx]\n","\n","            # Register each moving image to the fixed image\n","            for idx in moving_image_idx:\n","                print()\n","                print(f\"Registering image {idx+1} to image {fixed_image_idx+1} for subject {data[-1]['id']} ({i+1}/{num_subjects}))\")\n","                data[-1]['images'][:, :, :, idx], _ = register_image(fixed_image=fixed_image,\n","                                                                     moving_image=data[-1]['images'][:, :, :, idx],\n","                                                                     transform_type=transform_type,\n","                                                                     metric=metric,\n","                                                                     num_bins=num_bins,\n","                                                                     learning_rate=learning_rate,\n","                                                                     max_iters=max_iters,\n","                                                                     interp_method=interp_method,\n","                                                                     default_pixel_value=default_pixel_value,\n","                                                                     min_convergence=min_convergence,\n","                                                                     convergence_window=convergence_window,\n","                                                                     sitk_dtype=sitk_dtype)\n","\n","        # If a label path is specified, load the labels for the current subject\n","        if label_path is not None:\n","            labels = get_images(os.path.join(label_path, image_file))\n","            data[-1]['labels'] = labels\n","\n","    # Return the list of subjects with their corresponding images and labels\n","    return data\n"],"metadata":{"id":"XOR-tZHO0HH4","executionInfo":{"status":"ok","timestamp":1699648127247,"user_tz":300,"elapsed":4,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","dtype = torch.float32\n","\n","print(f\"device = {device}, dtype = {dtype}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KRvLAxZxb3Bs","executionInfo":{"status":"ok","timestamp":1699648127247,"user_tz":300,"elapsed":4,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}},"outputId":"774356da-abbc-4eba-ffb6-32cdce772b6e"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["device = cuda, dtype = torch.float32\n"]}]},{"cell_type":"code","source":["# torch.cuda.empty_cache()\n","# print(torch.cuda.memory_summary())"],"metadata":{"id":"mBkHwueqgj8G","executionInfo":{"status":"ok","timestamp":1699648127248,"user_tz":300,"elapsed":3,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["task_path = '/content/drive/MyDrive/data/MSD/Task01_BrainTumour'\n","images = access_images(task_path,\n","                       dtype = dtype,\n","                       sample_size = 100,\n","                       register_images = True,\n","                       num_bins = 25,\n","                       convergence_window = 10)"],"metadata":{"id":"-KTrw5nCMEGE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = \"/content/drive/MyDrive/MRI/images.pkl\"\n","with open(file_path, \"wb\") as file:\n","  pickle.dump(images, file)"],"metadata":{"id":"-sC6TU74Ra7F","executionInfo":{"status":"aborted","timestamp":1699648222555,"user_tz":300,"elapsed":33,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the file path where your data is stored\n","file_path = \"/content/drive/MyDrive/MRI/images.pkl\"\n","\n","# Open the file in binary read mode\n","with open(file_path, \"rb\") as file:\n","    # Load the data from the pickle file\n","    images = pickle.load(file)"],"metadata":{"id":"24aIfnx87c5D","executionInfo":{"status":"ok","timestamp":1699648601005,"user_tz":300,"elapsed":199090,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["scaler_t1 = MinMaxScaler(feature_range = (0, 1))\n","scaler_t1c = MinMaxScaler(feature_range = (0, 1))\n","scaler_t2 = MinMaxScaler(feature_range = (0, 1))\n","scaler_flair = MinMaxScaler(feature_range = (0, 1))\n","\n","i_subject = 1\n","\n","img = images[i_subject]['images']\n","img_shape = img.shape\n","\n","labels = images[i_subject]['labels']\n","\n","t1 = img[:, :, :, 0]\n","t1c = img[:, :, :, 1]\n","t2 = img[:, :, :, 2]\n","flair = img[:, :, :, 3]\n","\n","t1_n = scaler_t1.fit_transform(t1.reshape(-1,1))\n","t1c_n = scaler_t1.fit_transform(t1c.reshape(-1,1)).reshape(img_shape[:3])\n","t2_n = scaler_t1.fit_transform(t2.reshape(-1,1)).reshape(img_shape[:3])\n","flair_n = scaler_t1.fit_transform(flair.reshape(-1,1)).reshape(img_shape[:3])\n","\n","t1_n = torch.tensor(t1_n).to(device = device, dtype = dtype)\n","t1c_n = torch.tensor(t1c_n).to(device = device, dtype = dtype)\n","t2_n = torch.tensor(t2_n).to(device = device, dtype = dtype)\n","flair_n = torch.tensor(flair_n).to(device = device, dtype = dtype)\n"],"metadata":{"id":"sGaQ5fqjAvXi","executionInfo":{"status":"aborted","timestamp":1699648222555,"user_tz":300,"elapsed":28,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","i, j, k = 120, 120, 77\n","fig, ax = plt.subplots(5, 3, figsize = (20, 20))\n","ax[0,0].imshow(t1[i, :, :], cmap = 'gray')\n","ax[1,0].imshow(t1c[i, :, :], cmap = 'gray')\n","ax[2,0].imshow(t2[i, :, :], cmap = 'gray')\n","ax[3,0].imshow(flair[i, :, :], cmap = 'gray')\n","ax[4,0].imshow(labels[i, :, :])\n","\n","ax[0,1].imshow(t1[:, j, :], cmap = 'gray')\n","ax[1,1].imshow(t1c[:, j, :], cmap = 'gray')\n","ax[2,1].imshow(t2[:, j, :], cmap = 'gray')\n","ax[3,1].imshow(flair[:, j, :], cmap = 'gray')\n","ax[4,1].imshow(labels[:, j, :])\n","\n","ax[0,2].imshow(t1[:, :, k], cmap = 'gray')\n","ax[1,2].imshow(t1c[:, :, k], cmap = 'gray')\n","ax[2,2].imshow(t2[:, :, k], cmap = 'gray')\n","ax[3,2].imshow(flair[:, :, k], cmap = 'gray')\n","ax[4,2].imshow(labels[:, :, k])\n","\n","fig.tight_layout()"],"metadata":{"id":"ddGLzbLbuI7A","executionInfo":{"status":"aborted","timestamp":1699648222555,"user_tz":300,"elapsed":28,"user":{"displayName":"Brandon Henley","userId":"06235708662467000872"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"IvnhV9xZ67NG"},"execution_count":null,"outputs":[]}]}